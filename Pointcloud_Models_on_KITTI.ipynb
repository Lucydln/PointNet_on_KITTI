{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP9m1b-5hLRv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0loJ3FuHk1SG",
        "outputId": "2e166bfc-00a5-4874-f1c5-7c605d1735b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/garymk/kitti-3d-object-detection-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30.0G/30.0G [24:11<00:00, 22.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/garymk/kitti-3d-object-detection-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"garymk/kitti-3d-object-detection-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-2krOukfpK_",
        "outputId": "17719399-5ebf-4603-d861-ece1fe7c0a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted label mapping: {'Car': 0, 'Cyclist': 1, 'DontCare': 2, 'Misc': 3, 'Pedestrian': 4, 'Person_sitting': 5, 'Tram': 6, 'Truck': 7, 'Van': 8}\n"
          ]
        }
      ],
      "source": [
        "def extract_unique_labels(label_dir):\n",
        "    unique_labels = set()\n",
        "    for label_file in os.listdir(label_dir):\n",
        "        if label_file.endswith('.txt'):\n",
        "            with open(os.path.join(label_dir, label_file), 'r') as file:\n",
        "                for line in file:\n",
        "                    parts = line.strip().split()\n",
        "                    unique_labels.add(parts[0])  # Add the label (Class)\n",
        "    return sorted(unique_labels)\n",
        "\n",
        "# Extract unique labels from KITTI dataset\n",
        "label_dir = \"/root/.cache/kagglehub/datasets/garymk/kitti-3d-object-detection-dataset/versions/1/training/label_2\"\n",
        "unique_labels = extract_unique_labels(label_dir)\n",
        "\n",
        "# Map unique labels to numerical IDs\n",
        "label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "print(\"Extracted label mapping:\", label_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jLWjzCftyyG"
      },
      "outputs": [],
      "source": [
        "class KittiPointCloudDataset(Dataset):\n",
        "    def __init__(self, velodyne_dir, label_dir, label_to_id, num_points=1024):\n",
        "        self.velodyne_dir = velodyne_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.label_to_id = label_to_id\n",
        "        self.num_points = num_points\n",
        "\n",
        "        # List all velodyne files and label files\n",
        "        self.velodyne_files = sorted([f for f in os.listdir(velodyne_dir) if f.endswith('.bin')])\n",
        "        self.label_files = sorted([f for f in os.listdir(label_dir) if f.endswith('.txt')])\n",
        "\n",
        "        # Ensure point clouds and labels align\n",
        "        assert len(self.velodyne_files) == len(self.label_files), \"Mismatch between point clouds and labels\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.velodyne_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load point cloud\n",
        "        pc_file = os.path.join(self.velodyne_dir, self.velodyne_files[idx])\n",
        "        point_cloud = self.load_point_cloud(pc_file)\n",
        "\n",
        "        # Downsample or pad point cloud\n",
        "        if len(point_cloud) > self.num_points:\n",
        "            idxs = np.random.choice(len(point_cloud), self.num_points, replace=False)\n",
        "        else:\n",
        "            idxs = np.random.choice(len(point_cloud), self.num_points, replace=True)\n",
        "        point_cloud = point_cloud[idxs]\n",
        "\n",
        "        # Load and parse labels\n",
        "        label_file = os.path.join(self.label_dir, self.label_files[idx])\n",
        "        labels = self.parse_labels(label_file)\n",
        "\n",
        "        return torch.tensor(point_cloud, dtype=torch.float32), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def load_point_cloud(self, file_path):\n",
        "        \"\"\"Load point cloud from .bin file\"\"\"\n",
        "        point_cloud = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)  # x, y, z, intensity\n",
        "        return point_cloud[:, :3]  # Use only x, y, z\n",
        "\n",
        "    def parse_labels(self, label_file):\n",
        "        \"\"\"Parse label file and map labels to IDs using label_to_id\"\"\"\n",
        "        with open(label_file, 'r') as file:\n",
        "            for line in file:\n",
        "                parts = line.strip().split()\n",
        "                obj_class = parts[0]\n",
        "                if obj_class in self.label_to_id:\n",
        "                    return self.label_to_id[obj_class]\n",
        "        return self.label_to_id.get('DontCare', 0)  # Default to DontCare (0) if label is missing\n",
        "\n",
        "class KittiTestDataset(Dataset):\n",
        "    def __init__(self, velodyne_dir, num_points=1024):\n",
        "        self.velodyne_dir = velodyne_dir\n",
        "        self.num_points = num_points\n",
        "\n",
        "        # List all velodyne files\n",
        "        self.velodyne_files = sorted([f for f in os.listdir(velodyne_dir) if f.endswith('.bin')])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.velodyne_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load point cloud\n",
        "        pc_file = os.path.join(self.velodyne_dir, self.velodyne_files[idx])\n",
        "        point_cloud = self.load_point_cloud(pc_file)\n",
        "\n",
        "        # Downsample or pad point cloud\n",
        "        if len(point_cloud) > self.num_points:\n",
        "            idxs = np.random.choice(len(point_cloud), self.num_points, replace=False)\n",
        "        else:\n",
        "            idxs = np.random.choice(len(point_cloud), self.num_points, replace=True)\n",
        "        point_cloud = point_cloud[idxs]\n",
        "\n",
        "        return torch.tensor(point_cloud, dtype=torch.float32)\n",
        "\n",
        "    def load_point_cloud(self, file_path):\n",
        "        \"\"\"Load point cloud from .bin file\"\"\"\n",
        "        point_cloud = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)  # x, y, z, intensity\n",
        "        return point_cloud[:, :3]  # Use only x, y, z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85YR44MIuEEK",
        "outputId": "e881f301-52fe-4d27-8ff0-56c372b1d88a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Point Cloud Shape: torch.Size([16, 1024, 3])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Paths to KITTI directories\n",
        "velodyne_dir = \"/root/.cache/kagglehub/datasets/garymk/kitti-3d-object-detection-dataset/versions/1/training/velodyne\"\n",
        "label_dir = \"/root/.cache/kagglehub/datasets/garymk/kitti-3d-object-detection-dataset/versions/1/training/label_2\"\n",
        "\n",
        "# Extract unique labels and create mapping\n",
        "unique_labels = extract_unique_labels(label_dir)\n",
        "label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "\n",
        "# Create dataset and dataloader\n",
        "train_dataset = KittiPointCloudDataset(velodyne_dir, label_dir, label_to_id, num_points=1024)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define test dataset path\n",
        "test_velodyne_dir = \"/root/.cache/kagglehub/datasets/garymk/kitti-3d-object-detection-dataset/versions/1/testing/velodyne\"\n",
        "\n",
        "# Create test dataset and DataLoader\n",
        "test_dataset = KittiTestDataset(test_velodyne_dir, num_points=1024)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Inspect a batch\n",
        "for points, labels in train_loader:\n",
        "    print(\"Point Cloud Shape:\", points.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVYkxeitzvFh"
      },
      "source": [
        "# PointNet (from torch-3d source code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnzFNxievHeK"
      },
      "outputs": [],
      "source": [
        "class PointNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(PointNetClassifier, self).__init__()\n",
        "        # Shared MLP applied to each point\n",
        "        self.conv1 = nn.Conv1d(3, 64, 1)   # 3 -> 64\n",
        "        self.conv2 = nn.Conv1d(64, 128, 1)  # 64 -> 128\n",
        "        self.conv3 = nn.Conv1d(128, 1024, 1)  # 128 -> 1024\n",
        "\n",
        "        # Fully connected layers for global features\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "\n",
        "        # Dropout for regularization\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input: [batch_size, num_points, 3]\n",
        "        x = x.permute(0, 2, 1)  # [batch_size, 3, num_points]\n",
        "\n",
        "        # Shared MLP: Point-wise feature extraction\n",
        "        x = F.relu(self.conv1(x))  # [batch_size, 64, num_points]\n",
        "        x = F.relu(self.conv2(x))  # [batch_size, 128, num_points]\n",
        "        x = F.relu(self.conv3(x))  # [batch_size, 1024, num_points]\n",
        "\n",
        "        # Global feature: Max pooling across points\n",
        "        x = torch.max(x, 2)[0]  # [batch_size, 1024]\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))  # [batch_size, 512]\n",
        "        x = F.relu(self.fc2(x))  # [batch_size, 256]\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)  # [batch_size, num_classes]\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP911mKfuf3I",
        "outputId": "c3a08cdb-b357-4270-89fb-218aab6169a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8834, Accuracy: 0.7758\n",
            "Epoch [2/10], Loss: 0.7618, Accuracy: 0.8114\n",
            "Epoch [3/10], Loss: 0.7199, Accuracy: 0.8157\n",
            "Epoch [4/10], Loss: 0.6963, Accuracy: 0.8193\n",
            "Epoch [5/10], Loss: 0.6827, Accuracy: 0.8229\n",
            "Epoch [6/10], Loss: 0.6531, Accuracy: 0.8298\n",
            "Epoch [7/10], Loss: 0.6380, Accuracy: 0.8298\n",
            "Epoch [8/10], Loss: 0.5977, Accuracy: 0.8381\n",
            "Epoch [9/10], Loss: 0.5965, Accuracy: 0.8363\n",
            "Epoch [10/10], Loss: 0.5725, Accuracy: 0.8411\n"
          ]
        }
      ],
      "source": [
        "# Training Parameters\n",
        "num_classes = len(label_to_id)\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize model, optimizer, and loss function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PointNetClassifier(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for points, labels in train_loader:\n",
        "      points, labels = points.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(points)  # No need for reshaping\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      total += labels.size(0)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT_ZxPg2_lDK"
      },
      "source": [
        "test with testdataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yb3G0dpR_fTB"
      },
      "outputs": [],
      "source": [
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize a list to store predictions\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for points in test_loader:\n",
        "        points = points.to(device)  # Send points to GPU if available\n",
        "        outputs = model(points)  # Get predictions\n",
        "        _, predicted_classes = torch.max(outputs, 1)  # Predicted class indices\n",
        "        predictions.append(predicted_classes.cpu().numpy())  # Store predictions\n",
        "\n",
        "# Flatten predictions into a single array\n",
        "predictions = np.concatenate(predictions, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet++ Custom Implementation"
      ],
      "metadata": {
        "id": "rZJyGsWzf1lL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions:\n",
        "def farthest_point_sample(xyz, npoint):\n",
        "    batch_size, n, _ = xyz.shape\n",
        "    device = xyz.device\n",
        "    centroids = torch.zeros(batch_size, npoint, dtype=torch.long).to(device)\n",
        "    distance = torch.ones(batch_size, n).to(device) * 1e10\n",
        "    farthest = torch.randint(0, n, (batch_size,), dtype=torch.long).to(device)\n",
        "    batch_indices = torch.arange(batch_size, dtype=torch.long).to(device)\n",
        "\n",
        "    for i in range(npoint):\n",
        "        centroids[:, i] = farthest\n",
        "        centroid = xyz[batch_indices, farthest, :].unsqueeze(1)  # [B, 1, 3]\n",
        "        dist = torch.sum((xyz - centroid) ** 2, -1)  # Squared distance [B, N]\n",
        "        mask = dist < distance\n",
        "        distance[mask] = dist[mask]\n",
        "        farthest = torch.max(distance, -1)[1]  # Index of the farthest point\n",
        "\n",
        "    return centroids\n",
        "\n",
        "\n",
        "def gather_points(xyz, idx):\n",
        "    batch_size, n, _ = xyz.shape\n",
        "\n",
        "    if idx.dim() == 2:  # Case 1: [B, npoint]\n",
        "        _, npoint = idx.shape\n",
        "        idx = idx.view(-1)  # Flatten indices for batch processing\n",
        "        gathered_xyz = xyz.reshape(batch_size * n, -1)[idx, :]  # Gather points\n",
        "        gathered_xyz = gathered_xyz.reshape(batch_size, npoint, -1)  # Reshape back\n",
        "    elif idx.dim() == 3:  # Case 2: [B, npoint, nsample]\n",
        "        _, npoint, nsample = idx.shape\n",
        "        idx_base = torch.arange(0, batch_size, device=xyz.device).view(-1, 1, 1) * n\n",
        "        idx = idx + idx_base  # Flatten indices for batch processing\n",
        "        idx = idx.reshape(-1)  # Flatten completely\n",
        "        gathered_xyz = xyz.reshape(batch_size * n, -1)[idx, :]  # Gather points\n",
        "        gathered_xyz = gathered_xyz.reshape(batch_size, npoint, nsample, -1)  # Reshape back\n",
        "\n",
        "    return gathered_xyz\n",
        "\n",
        "\n",
        "def query_and_group(xyz, new_xyz, points, radius, nsample):\n",
        "    B, N, _ = xyz.shape\n",
        "    _, npoint, _ = new_xyz.shape\n",
        "\n",
        "    # Compute squared distances between sampled points and all points\n",
        "    sqrdists = square_distance(new_xyz, xyz)  # [B, npoint, N]\n",
        "\n",
        "    # Find indices of the nearest neighbors\n",
        "    group_idx = sqrdists.argsort(dim=-1)[:, :, :nsample]  # [B, npoint, nsample]\n",
        "\n",
        "    # Gather the grouped xyz coordinates\n",
        "    grouped_xyz = gather_points(xyz, group_idx)  # [B, npoint, nsample, 3]\n",
        "    grouped_xyz = grouped_xyz - new_xyz.unsqueeze(2)  # Local coordinates [B, npoint, nsample, 3]\n",
        "\n",
        "    if points is not None:\n",
        "        grouped_points = gather_points(points.transpose(1, 2), group_idx).permute(0, 3, 2, 1)  # [B, C, nsample, npoint]\n",
        "        new_points = torch.cat([grouped_xyz.permute(0, 3, 2, 1), grouped_points], dim=1)  # [B, C+3, nsample, npoint]\n",
        "    else:\n",
        "        new_points = grouped_xyz.permute(0, 3, 2, 1)  # [B, 3, nsample, npoint]\n",
        "\n",
        "    return new_points\n",
        "\n",
        "\n",
        "def square_distance(src, dst):\n",
        "    B, N, _ = src.shape\n",
        "    _, M, _ = dst.shape\n",
        "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))  # [B, N, M]\n",
        "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
        "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
        "    return dist\n",
        "\n",
        "class SetAbstraction(nn.Module):\n",
        "    def __init__(self, npoint, radius, nsample, in_channel, mlp):\n",
        "        super(SetAbstraction, self).__init__()\n",
        "        self.npoint = npoint\n",
        "        self.radius = radius\n",
        "        self.nsample = nsample\n",
        "\n",
        "        # Include x, y, z coordinates in the input channel count\n",
        "        last_channel = in_channel + 3  # Add (x, y, z)\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))  # Conv2D expects [B, C_in, nsample, npoint]\n",
        "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
        "            last_channel = out_channel\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        if self.npoint is not None:\n",
        "            idx = farthest_point_sample(xyz, self.npoint)  # [B, npoint]\n",
        "            new_xyz = gather_points(xyz, idx)  # [B, npoint, 3]\n",
        "        else:\n",
        "            new_xyz = xyz  # Use all points if npoint is None\n",
        "\n",
        "        grouped_points = query_and_group(xyz, new_xyz, points, self.radius, self.nsample)  # [B, C+3, nsample, npoint]\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "            grouped_points = F.relu(self.mlp_bns[i](conv(grouped_points)))  # [B, out_channel, nsample, npoint]\n",
        "\n",
        "        # Max pooling over nsample dimension\n",
        "        new_points = torch.max(grouped_points, 2)[0]  # [B, mlp[-1], npoint]\n",
        "        return new_xyz, new_points\n",
        "\n",
        "\n",
        "# Define PointNet++ model\n",
        "class PointNetPlusPlus(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(PointNetPlusPlus, self).__init__()\n",
        "\n",
        "        # Set Abstraction layers\n",
        "        self.sa1 = SetAbstraction(npoint=512, radius=0.2, nsample=32, in_channel=0, mlp=[64, 64, 128])\n",
        "        self.sa2 = SetAbstraction(npoint=128, radius=0.4, nsample=64, in_channel=128, mlp=[128, 128, 256])\n",
        "        self.sa3 = SetAbstraction(npoint=None, radius=None, nsample=None, in_channel=256, mlp=[256, 512, 1024])\n",
        "\n",
        "        # Fully connected layers for classification\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, xyz):\n",
        "        batch_size, _, _ = xyz.shape\n",
        "\n",
        "        # Hierarchical feature extraction\n",
        "        l1_xyz, l1_points = self.sa1(xyz, None)       # Layer 1: [B, 512, 128]\n",
        "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)  # Layer 2: [B, 128, 256]\n",
        "        _, l3_points = self.sa3(l2_xyz, l2_points)    # Layer 3: [B, 1024, npoint]\n",
        "\n",
        "        # Apply global pooling over the npoint dimension\n",
        "        x = torch.max(l3_points, dim=-1)[0]           # [B, 1024]\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))                      # [B, 512]\n",
        "        x = F.relu(self.fc2(x))                      # [B, 256]\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)                              # [B, num_classes]\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QY195cm7qkEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KittiPointCloudDataset(Dataset):\n",
        "    def __init__(self, velodyne_dir, label_dir, label_to_id, num_points=1024):\n",
        "        self.velodyne_dir = velodyne_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.label_to_id = label_to_id\n",
        "        self.num_points = num_points\n",
        "\n",
        "        # List all velodyne files and label files\n",
        "        self.velodyne_files = sorted([f for f in os.listdir(velodyne_dir) if f.endswith('.bin')])\n",
        "        self.label_files = sorted([f for f in os.listdir(label_dir) if f.endswith('.txt')])\n",
        "\n",
        "        # Ensure point clouds and labels align\n",
        "        assert len(self.velodyne_files) == len(self.label_files), \"Mismatch between point clouds and labels\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.velodyne_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load point cloud\n",
        "        pc_file = os.path.join(self.velodyne_dir, self.velodyne_files[idx])\n",
        "        point_cloud = self.load_point_cloud(pc_file)\n",
        "\n",
        "        # Downsample or pad point cloud to fixed number of points\n",
        "        if len(point_cloud) > self.num_points:\n",
        "            idxs = np.random.choice(len(point_cloud), self.num_points, replace=False)\n",
        "        else:\n",
        "            idxs = np.random.choice(len(point_cloud), self.num_points, replace=True)\n",
        "        point_cloud = point_cloud[idxs]\n",
        "\n",
        "        # Load and parse labels\n",
        "        label_file = os.path.join(self.label_dir, self.label_files[idx])\n",
        "        labels = self.parse_labels(label_file)\n",
        "\n",
        "        return torch.tensor(point_cloud, dtype=torch.float32), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def load_point_cloud(self, file_path):\n",
        "        \"\"\"Load point cloud from .bin file.\"\"\"\n",
        "        point_cloud = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)  # x, y, z, intensity\n",
        "        return point_cloud[:, :3]  # Use only x, y, z\n",
        "\n",
        "    def parse_labels(self, label_file):\n",
        "        \"\"\"Parse label file and map labels to IDs using label_to_id.\"\"\"\n",
        "        with open(label_file, 'r') as file:\n",
        "            for line in file:\n",
        "                parts = line.strip().split()\n",
        "                obj_class = parts[0]\n",
        "                if obj_class in self.label_to_id:\n",
        "                    return self.label_to_id[obj_class]\n",
        "        return self.label_to_id.get('DontCare', 0)  # Default to DontCare (0) if label is missing\n",
        "\n",
        "\n",
        "class KittiTestDataset(Dataset):\n",
        "    def __init__(self, velodyne_dir, num_points=1024):\n",
        "        self.velodyne_dir = velodyne_dir\n",
        "        self.num_points = num_points\n",
        "\n",
        "        # List all velodyne files\n",
        "        self.velodyne_files = sorted([f for f in os.listdir(velodyne_dir) if f.endswith('.bin')])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.velodyne_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load point cloud\n",
        "        pc_file = os.path.join(self.velodyne_dir, self.velodyne_files[idx])\n",
        "        point_cloud = self.load_point_cloud(pc_file)\n",
        "\n",
        "        # Downsample or pad point cloud to fixed number of points\n",
        "        if len(point_cloud) > self.num_points:\n",
        "            idxs = np.random.choice(len(point_cloud), self.num_points, replace=False)\n",
        "        else:\n",
        "            idxs = np.random.choice(len(point_cloud), self.num_points, replace=True)\n",
        "        point_cloud = point_cloud[idxs]\n",
        "\n",
        "        return torch.tensor(point_cloud, dtype=torch.float32)\n",
        "\n",
        "    def load_point_cloud(self, file_path):\n",
        "        \"\"\"Load point cloud from .bin file.\"\"\"\n",
        "        point_cloud = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)  # x, y, z, intensity\n",
        "        return point_cloud[:, :3]  # Use only x, y, z\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Paths to KITTI directories\n",
        "velodyne_dir = \"/root/.cache/kagglehub/datasets/garymk/kitti-3d-object-detection-dataset/versions/1/training/velodyne\"\n",
        "label_dir = \"/root/.cache/kagglehub/datasets/garymk/kitti-3d-object-detection-dataset/versions/1/training/label_2\"\n",
        "\n",
        "# Extract unique labels and create mapping\n",
        "unique_labels = extract_unique_labels(label_dir)\n",
        "label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "\n",
        "# Create train dataset and DataLoader\n",
        "train_dataset = KittiPointCloudDataset(velodyne_dir, label_dir, label_to_id, num_points=1024)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=lambda x: collate_fn(x))\n",
        "\n",
        "# Create test dataset and DataLoader\n",
        "test_velodyne_dir = \"/root/.cache/kagglehub/datasets/garymk/kitti-3d-object-detection-dataset/versions/1/testing/velodyne\"\n",
        "test_dataset = KittiTestDataset(test_velodyne_dir, num_points=1024)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Custom collate function to handle batching\n",
        "def collate_fn(batch):\n",
        "    points, labels = zip(*batch)\n",
        "    return torch.stack(points), torch.tensor(labels)\n",
        "\n",
        "\n",
        "for points, labels in train_loader:\n",
        "    print(\"Point Cloud Shape:\", points.shape)  # Expected: [B, N, 3]\n",
        "    print(\"Labels Shape:\", labels.shape)  # Expected: [B]\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exk-2chx3HNd",
        "outputId": "19071f45-79df-4c88-bb60-67c3c6983e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Point Cloud Shape: torch.Size([16, 1024, 3])\n",
            "Labels Shape: torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "\n",
        "B, N, C = 16, 1024, 3\n",
        "xyz = torch.rand(B, N, C)  # Simulate a batched point cloud\n",
        "\n",
        "# Test farthest point sampling\n",
        "npoint = 512\n",
        "fps_idx = farthest_point_sample(xyz, npoint)  # [B, npoint]\n",
        "fps_xyz = gather_points(xyz, fps_idx)         # [B, npoint, 3]\n",
        "print(\"FPS Output Shape:\", fps_xyz.shape)\n",
        "\n",
        "# Test query and group\n",
        "radius = 0.2\n",
        "nsample = 32\n",
        "grouped_points = query_and_group(xyz, fps_xyz, None, radius, nsample)  # [B, 3, nsample, npoint]\n",
        "print(\"Grouped Points Shape:\", grouped_points.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c95Y0UyD4MZ0",
        "outputId": "617f99bf-534d-4f9c-89c8-4208ab11e99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPS Output Shape: torch.Size([16, 512, 3])\n",
            "Grouped Points Shape: torch.Size([16, 3, 32, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "num_classes = len(label_to_id)\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize model, optimizer, and loss function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PointNetPlusPlus(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for points, labels in train_loader:\n",
        "      points, labels = points.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(points)  # No need for reshaping\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      total += labels.size(0)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv4llR6Cf0mA",
        "outputId": "6ca8edfd-058f-4153-d740-69c3f2f3f273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.9382, Accuracy: 0.7548\n",
            "Epoch [2/10], Loss: 0.8408, Accuracy: 0.7925\n",
            "Epoch [3/10], Loss: 0.8016, Accuracy: 0.8022\n",
            "Epoch [4/10], Loss: 0.7857, Accuracy: 0.8030\n",
            "Epoch [5/10], Loss: 0.7481, Accuracy: 0.8078\n",
            "Epoch [6/10], Loss: 0.7462, Accuracy: 0.8067\n",
            "Epoch [7/10], Loss: 0.7225, Accuracy: 0.8110\n",
            "Epoch [8/10], Loss: 0.7095, Accuracy: 0.8174\n",
            "Epoch [9/10], Loss: 0.7088, Accuracy: 0.8158\n",
            "Epoch [10/10], Loss: 0.6929, Accuracy: 0.8183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize a list to store predictions\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for points in test_loader:\n",
        "        points = points.to(device)  # Send points to GPU if available\n",
        "        outputs = model(points)  # Get predictions\n",
        "        _, predicted_classes = torch.max(outputs, 1)  # Predicted class indices\n",
        "        predictions.append(predicted_classes.cpu().numpy())  # Store predictions\n",
        "\n",
        "# Flatten predictions into a single array\n",
        "predictions = np.concatenate(predictions, axis=0)"
      ],
      "metadata": {
        "id": "dSEaKyLSqxrL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}